# Decision Trees

## Terminology

We have a `dataset`, which consists of `points`. Each point has `input_features` and at least the training dataset has a `class_label`.

A `classifier`, such as a decision tree or a decision forest, is initialized with a dataset (and optionally, extra classifier-specific parameters). It can then `classify` new unlabeled points.

We can evaluate the performance of a classifier using a test dataset, where we generate a `confusion_matrix` of predicted vs. actual class labels, which can tell us various things about how the classifier performed. Some classifiers, such as decision forests, may have their own internal performance evaluation mechanisms, such as the "out of bag" error.

## Brainstorm

Why binary and not multi-branch?
Why > or < and not in/out of a range?


```
Dataset#best_binary_split
    returns
        predicate
        set1
        set2

best_predicate = None
max_information_gain = 0

for attribute in categorical_attributes:
    for value in possible_values_of(attribute):
        counters = [EntropyCounter(), EntropyCounter()]
        for point in points:
            counters[point[attribute] == value].record(point[outcome])
        information_gain = sum(counter.entropy() for counter in counters) 
        predicate = [attribute, ==, value]
for attribute in numerical_attributes:
    for value in some_binning_of(attribute):
        counters = [EntropyCounter(), EntropyCounter()]
        for point in points:
            counters[point[attribute] > value].record(point[outcome])
        information_gain = sum(counter.entropy() for counter in counters)
        predicate = [attribute, >, value]


max_by(entropy,
    for point in points:
        for predicate in predicates:
            entropies[predicate].record(predicate(point), outcome(point))
    
for attribute in attributes:
    for predicate in possible_predicates_for(attribute);
            


```

